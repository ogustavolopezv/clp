{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /___/ .__/\\_,_/_/ /_/\\_\\   version 3.0.1\n",
      "      /_/\n",
      "                        \n",
      "Using Scala version 2.12.10, OpenJDK 64-Bit Server VM, 1.8.0_275\n",
      "Branch HEAD\n",
      "Compiled by user ubuntu on 2020-08-28T08:58:35Z\n",
      "Revision 2b147c4cd50da32fe2b4167f97c8142102a0510d\n",
      "Url https://gitbox.apache.org/repos/asf/spark.git\n",
      "Type --help for more information.\n"
     ]
    }
   ],
   "source": [
    "!spark-submit --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SQLContext, SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.mllib.linalg.distributed import RowMatrix\n",
    "from pyspark.mllib.util import MLUtils\n",
    "from pyspark.mllib.feature import LabeledPoint\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics, MultilabelMetrics\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import PCA, StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spark Session\n",
    "appName = \"clip\"\n",
    "master = \"local\"\n",
    "\n",
    "conf = (SparkConf()\n",
    "    .set(\"spark.driver.maxResultSize\", \"8g\")\n",
    "    .set(\"spark.driver.memory\", \"16g\") )\n",
    "\n",
    "sc = SparkContext(master, appName, conf = conf)\n",
    "sqlContext = SQLContext(sc)\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(appName) \\\n",
    "    .master(master) \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0------------------------------\n",
      " transaction_id | 99899e9e02c4b41fc... \n",
      " timestamp      | 155270.0             \n",
      " amount         | 12.0                 \n",
      " variable_01    | -0.0713300864873049  \n",
      " variable_02    | -0.0328999520808001  \n",
      " variable_03    | 0.10998943181331698  \n",
      " variable_04    | 0.33988859549026507  \n",
      " variable_05    | -0.6261306478334321  \n",
      " variable_06    | -0.11685326903066098 \n",
      " variable_07    | 1.22082562064008     \n",
      " variable_08    | 0.39404086545839706  \n",
      " variable_09    | 0.0517052313610874   \n",
      " variable_10    | 0.7000841408460489   \n",
      " variable_11    | -1.18526338095099    \n",
      " variable_12    | -0.183050156425376   \n",
      " variable_13    | 1.05102866940126     \n",
      " variable_14    | 0.267423177397213    \n",
      " variable_15    | -0.22056869472414398 \n",
      " variable_16    | 1.3582066520249299   \n",
      " variable_17    | -0.321922279007069   \n",
      " variable_18    | -1.12124634073183    \n",
      " variable_19    | 0.852399772357995    \n",
      " variable_20    | -0.6359347108629929  \n",
      " variable_21    | -0.445326616622055   \n",
      " variable_22    | -0.251412438032025   \n",
      " variable_23    | -0.989219027751904   \n",
      " variable_24    | -0.168169336108441   \n",
      " variable_25    | -1.05494363199881    \n",
      " variable_26    | -1.60317603205376    \n",
      " variable_27    | -0.6166395472239511  \n",
      " variable_28    | 2.28307794239386     \n",
      " variable_29    | 0.3739640681652777   \n",
      " variable_30    | 1.57654300410189     \n",
      " variable_31    | -0.9415571416324247  \n",
      " variable_32    | -0.10527984665856033 \n",
      " is_fraud       | 0                    \n",
      "only showing top 1 row\n",
      "\n",
      "root\n",
      " |-- transaction_id: string (nullable = true)\n",
      " |-- timestamp: double (nullable = true)\n",
      " |-- amount: double (nullable = true)\n",
      " |-- variable_01: double (nullable = true)\n",
      " |-- variable_02: double (nullable = true)\n",
      " |-- variable_03: double (nullable = true)\n",
      " |-- variable_04: double (nullable = true)\n",
      " |-- variable_05: double (nullable = true)\n",
      " |-- variable_06: double (nullable = true)\n",
      " |-- variable_07: double (nullable = true)\n",
      " |-- variable_08: double (nullable = true)\n",
      " |-- variable_09: double (nullable = true)\n",
      " |-- variable_10: double (nullable = true)\n",
      " |-- variable_11: double (nullable = true)\n",
      " |-- variable_12: double (nullable = true)\n",
      " |-- variable_13: double (nullable = true)\n",
      " |-- variable_14: double (nullable = true)\n",
      " |-- variable_15: double (nullable = true)\n",
      " |-- variable_16: double (nullable = true)\n",
      " |-- variable_17: double (nullable = true)\n",
      " |-- variable_18: double (nullable = true)\n",
      " |-- variable_19: double (nullable = true)\n",
      " |-- variable_20: double (nullable = true)\n",
      " |-- variable_21: double (nullable = true)\n",
      " |-- variable_22: double (nullable = true)\n",
      " |-- variable_23: double (nullable = true)\n",
      " |-- variable_24: double (nullable = true)\n",
      " |-- variable_25: double (nullable = true)\n",
      " |-- variable_26: double (nullable = true)\n",
      " |-- variable_27: double (nullable = true)\n",
      " |-- variable_28: double (nullable = true)\n",
      " |-- variable_29: double (nullable = true)\n",
      " |-- variable_30: double (nullable = true)\n",
      " |-- variable_31: double (nullable = true)\n",
      " |-- variable_32: double (nullable = true)\n",
      " |-- is_fraud: integer (nullable = true)\n",
      "\n",
      "Total count: 284807\n",
      "Is fraud count: 492\n",
      "Is not fraud count: 284315\n"
     ]
    }
   ],
   "source": [
    "# Inbound\n",
    "raw = spark.read.csv(\"raw/datos.csv\", header = True, inferSchema = True)\n",
    "raw.show(1, vertical = True)\n",
    "raw.printSchema()\n",
    "\n",
    "# Total count\n",
    "print(\"Total count: \" + str(raw.count()))\n",
    "# Is fraud count\n",
    "print(\"Is fraud count: \" + str(raw.filter(F.col(\"is_fraud\") == 1.0).count()))\n",
    "# Is not fraud count\n",
    "print(\"Is not fraud count: \" + str(raw.filter(F.col(\"is_fraud\") == 0.0).count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+-----------------+--------------------+\n",
      "|summary|        timestamp|           amount|            is_fraud|\n",
      "+-------+-----------------+-----------------+--------------------+\n",
      "|  count|           284807|           284807|              284807|\n",
      "|   mean|94813.85957508067|88.34961925094817|0.001727485630620034|\n",
      "| stddev|47488.14595456631|250.1201092401885| 0.04152718963546499|\n",
      "|    min|              0.0|              0.0|                   0|\n",
      "|    25%|          54196.0|              5.6|                   0|\n",
      "|    50%|          84687.0|             22.0|                   0|\n",
      "|    75%|         139317.0|            77.15|                   0|\n",
      "|    max|         172792.0|         25691.16|                   1|\n",
      "+-------+-----------------+-----------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# General statistics\n",
    "raw.select(\"timestamp\", \"amount\", \"is_fraud\").summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary|           amount|\n",
      "+-------+-----------------+\n",
      "|  count|              492|\n",
      "|   mean|122.2113211382113|\n",
      "| stddev|256.6832882977122|\n",
      "|    min|              0.0|\n",
      "|    25%|              1.0|\n",
      "|    50%|             9.21|\n",
      "|    75%|           105.89|\n",
      "|    max|          2125.87|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Distribution of is_fraud\n",
    "raw.select(\"amount\").filter(F.col(\"is_fraud\") == 1.0).summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|summary|         variable_01|         variable_02|         variable_03|         variable_04|         variable_05|         variable_06|         variable_07|         variable_08|         variable_09|         variable_10|\n",
      "+-------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|  count|              284807|              284807|              284807|              284807|              284807|              284807|              284807|              284807|              284807|              284807|\n",
      "|   mean|-1.19352278837118...|-3.50871749491060...|1.690591100150187...|5.482371085797822...|4.470221848251438...|2.674449057554159...|-3.51769885368597...|1.473441803536834...|6.554396048513327...|1.024367627713707...|\n",
      "| stddev|  0.3300832641602531|   0.403632494965032| 0.48222701326105727|  0.5212780705409432|  0.6056470678271576|  0.6244602955949902|  0.7257015604409128|  0.7345240143713107|  0.7709250248871183|  0.8140405007685836|\n",
      "|    min| -15.430083905534898|   -22.5656793207827|   -2.60455055280817|   -10.2953970749851|   -2.83662691870341| -44.807735203791296|    -10.933143697655|   -34.8303821448146|    -54.497720494566|   -7.21352743017759|\n",
      "|    25%| -0.0529642839114431| -0.0708602654275237|  -0.327023776881852|  -0.317114946103503|   -0.35459868145884|  -0.161846401993962|  -0.542208662439179|  -0.228432785326811|-0.21176106056564004|  -0.456441834076136|\n",
      "|    50%|  0.0112438566463369| 0.00132242001200164| -0.0521442494533822|  0.0164781769739571| 0.04095973092795299| -0.0112087737156578|0.006674895161151...| -0.0294331674553935| -0.0625105717774576| 0.00366948321091544|\n",
      "|    75%|  0.0782697790473533| 0.09104645881909199|   0.240844483599605| 0.35064374022321393|   0.439505786869821|   0.147614648623085|   0.528530804915113|   0.186367908084631|   0.133046751004668| 0.45883668900881897|\n",
      "|    max|    33.8478078188831|  31.612198106136304|  3.5173456116237998|    7.51958867870916|    4.58454913689817|    22.5284116897749|    10.5030900899454|    27.2028391573154|    39.4209042482199|    5.59197142733558|\n",
      "+-------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw.select(\"variable_01\", \"variable_02\", \"variable_03\", \"variable_04\", \"variable_05\", \"variable_06\", \"variable_07\", \"variable_08\", \"variable_09\", \"variable_10\").summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|summary|         variable_11|         variable_12|         variable_13|         variable_14|         variable_15|         variable_16|         variable_17|         variable_18|         variable_19|         variable_20|\n",
      "+-------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|  count|              284807|              284807|              284807|              284807|              284807|              284807|              284807|              284807|              284807|              284807|\n",
      "|   mean|9.582111884565311...|-3.86547702404329...|1.456776393364761...|4.873085685764354...|1.200757771829120...|8.82169017491745E-16|-1.23363952423449...|1.696778258417663...|2.255318981370298...|-2.41679632768577...|\n",
      "| stddev|  0.8381762095288418|  0.8493370636743873|  0.8762528873883674|  0.9153160116104367|  0.9585956112570564|  0.9952742301251557|  0.9992013895301536|  1.0207130277115548|   1.088849765402518|  1.0986320892243189|\n",
      "|    min|  -9.498745921046769| -25.162799369324798|   -14.1298545174931|   -4.49894467676621|   -19.2143254902614| -5.7918812063208405| -18.683714633344298|   -4.79747346479757|   -24.5882624372475|   -13.4340663182301|\n",
      "|    25%|-0.49878375226935706|-0.48374274739310497|-0.46807302999270795| -0.5830270961249631|-0.42567980069391603| -0.6486259330645401|-0.40581447093725503| -0.7624679297307901|  -0.535607690875844| -0.6431726010526291|\n",
      "|    50%|-0.00367364358209277| -0.0656996312159361|  0.0663470592812846|  0.0479649670311146|  0.0504886888779946| -0.0136600364200887| 0.13995138985279298| -0.0327635421391453| -0.0929759079019414| -0.0514772826725866|\n",
      "|    75%|   0.500587997476193| 0.39967667924538597|   0.523199753730276|   0.648682450736524| 0.49311188217865604|  0.6623264459409289|   0.618032401846913|   0.739380581854956|   0.453706341291233|  0.5968907979297221|\n",
      "|    max|    5.04106918541184|    9.25352625047285|  17.315111517627802|    8.87774159774277|    10.5267660517847|   7.126882958593759|  7.8483920756445995|  12.018913181619899|    23.7451361206545|    15.5949946071278|\n",
      "+-------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw.select(\"variable_11\", \"variable_12\", \"variable_13\", \"variable_14\", \"variable_15\", \"variable_16\", \"variable_17\", \"variable_18\", \"variable_19\", \"variable_20\").summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|summary|         variable_21|         variable_22|         variable_23|         variable_24|         variable_25|         variable_26|         variable_27|         variable_28|         variable_29|         variable_30|         variable_31|         variable_32|\n",
      "+-------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|  count|              284807|              284807|              284807|              284807|              284807|              284807|              284807|              284807|              284807|              284807|              284807|              284807|\n",
      "|   mean|9.031255213009381...|-5.84935938464690...|1.495296443223564...|9.919411803018039...|2.057504554342808...|-1.43542071805444...|3.648427520305226...|1.157846835457915...|5.766631091038233...|2.175684266895365...|-1.57872328695920...|-1.19671616038020...|\n",
      "| stddev|  1.1943529026692015|  1.2370935981826636|   1.332271089757563|  1.3802467340314433|  1.4158685749409259|  1.5162550051777577|   1.651308579476995|  1.9586958038574875|  1.6395718450875807|  1.3143793310825598|   4.357099086915284|   1.291623983888105|\n",
      "|    min|  -73.21671845526741|   -43.5572415712451|   -26.1605059358433| -113.74330671114599|   -5.68317119816995|   -48.3255893623954|   -72.7157275629303|    -56.407509631329|  -8.855471879547778|  -21.19478177623965| -203.67710755306064|  -72.21017382650464|\n",
      "|    25%|  -0.208631406248624|  -0.554094984266228|  -0.768511206827042| -0.6917469095791859| -0.8489324273342149|  -0.890499463968175| -0.5986552796935699|  -0.920363115606643| -1.1118808413982968|  -0.702109544989062| -0.6991285476310489|-0.22675284936807585|\n",
      "|    50%|  0.0222927260628561|  0.0399526777203012|  -0.274257249648141| -0.0545353142278145| -0.0200311696674349| 0.17970751478081898|  0.0654155158602033|  0.0178629377002415| -0.1772904481414995| 0.09952058892192692|  0.1484189077316471|0.004231744038405...|\n",
      "|    75%|   0.327360611873669|  0.5703374856678349|   0.398199917696517|  0.6117508733499329|   0.743389103164902|  1.0268686373457299|  0.8037808709342041|  1.3156013054723898|   0.818871244238657|  0.7847996305954141|  1.0331610834250635| 0.29134866822109434|\n",
      "|    max|    20.0072083651213|    120.589493945238|    73.3016255459646|    34.8016658766686|    16.8753440335975|    9.38255843282114|    22.0577289904909|    2.45492999121121|  11.958975079520918|  25.972667276441705|   446.7910632092569|  101.15903393963617|\n",
      "+-------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw.select(\"variable_21\", \"variable_22\", \"variable_23\", \"variable_24\", \"variable_25\", \"variable_26\", \"variable_27\", \"variable_28\", \"variable_29\", \"variable_30\", \"variable_31\", \"variable_32\").summary().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier (MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## v. Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Testing over training data...\n",
      "Accuracy = 0.9997963533199675\n"
     ]
    }
   ],
   "source": [
    "# SVMLIB format, to abstract labels and features.\n",
    "!rm -r libsvm/\n",
    "r = raw.rdd.map(lambda line:LabeledPoint(line[-1], Vectors.dense(line[3:35])))\n",
    "MLUtils.saveAsLibSVMFile(r, \"libsvm/\")\n",
    "libsvm = spark.read.format(\"libsvm\").load(\"libsvm/\")\n",
    "# libsvm.show(truncate = True)\n",
    "\n",
    "# Classifier (MLP).\n",
    "data = libsvm\n",
    "# Define network\n",
    "layers = [32, 23, 18, 2]\n",
    "trainer = MultilayerPerceptronClassifier(maxIter = 100, layers = layers, \n",
    "                                         blockSize = 128, seed = 1234)\n",
    "# Training.\n",
    "print(\"Training...\")\n",
    "model = trainer.fit(data)\n",
    "# Accuracy.\n",
    "print(\"Testing over training data...\")\n",
    "result = model.transform(data)\n",
    "predictionAndLabels = result.select(\"prediction\", \"label\")\n",
    "evaluator = MulticlassClassificationEvaluator(metricName = \"accuracy\")\n",
    "print(\"Accuracy = \" + str(evaluator.evaluate(predictionAndLabels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## v. 32 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Testing...\n",
      "Test set accuracy = 0.9994486156733928\n",
      "Confusion matrix\n",
      "[[8.5056e+04 2.4000e+01]\n",
      " [2.3000e+01 1.3700e+02]]\n",
      "Accuracy\n",
      "0.9994486156733928\n",
      "True positive rate, is fraud\n",
      "0.85625\n",
      "True positive rate, is not fraud\n",
      "0.9997179125528914\n"
     ]
    }
   ],
   "source": [
    "# SVMLIB format\n",
    "!rm -r libsvm/\n",
    "r = raw.rdd.map(lambda line:LabeledPoint(line[-1], Vectors.dense(line[3:35])))\n",
    "MLUtils.saveAsLibSVMFile(r, \"libsvm/\")\n",
    "libsvm = spark.read.format(\"libsvm\").load(\"libsvm/\")\n",
    "# libsvm.show(truncate = True)\n",
    "\n",
    "# Classifier (MLP)\n",
    "data = libsvm\n",
    "# Train and test split.\n",
    "splits = data.randomSplit([0.7, 0.3], 1234)\n",
    "train = splits[0]\n",
    "test = splits[1]\n",
    "# Define network\n",
    "layers = [32, 23, 18, 2]\n",
    "trainer = MultilayerPerceptronClassifier(maxIter = 100, layers = layers, \n",
    "                                         blockSize = 128, seed = 1234)\n",
    "# Training.\n",
    "print(\"Training...\")\n",
    "model = trainer.fit(train)\n",
    "# Accuracy of test.\n",
    "print(\"Testing...\")\n",
    "result = model.transform(test)\n",
    "predictionAndLabels = result.select(\"prediction\", \"label\")\n",
    "evaluator = MulticlassClassificationEvaluator(metricName = \"accuracy\")\n",
    "print(\"Test set accuracy = \" + str(evaluator.evaluate(predictionAndLabels)))\n",
    "\n",
    "# Metrics \n",
    "metrics = MulticlassMetrics(predictionAndLabels.rdd)\n",
    "\n",
    "print(\"Confusion matrix\")\n",
    "print(metrics.confusionMatrix().toArray())\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator()\n",
    "evaluator.setPredictionCol(\"prediction\")\n",
    "\n",
    "print(\"Accuracy\")\n",
    "print(evaluator.evaluate(predictionAndLabels, {evaluator.metricName: \"accuracy\"}))\n",
    "print(\"True positive rate, is fraud\")\n",
    "print(evaluator.evaluate(predictionAndLabels, {evaluator.metricName: \"truePositiveRateByLabel\",\n",
    "    evaluator.metricLabel: 1.0}))\n",
    "print(\"True positive rate, is not fraud\")\n",
    "print(evaluator.evaluate(predictionAndLabels, {evaluator.metricName: \"truePositiveRateByLabel\",\n",
    "    evaluator.metricLabel: 0.0}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## v. Features Normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Testing...\n",
      "Test set accuracy = 0.9992022524636321\n",
      "Confusion matrix\n",
      "[[8.5047e+04 3.3000e+01]\n",
      " [3.5000e+01 1.2500e+02]]\n",
      "Accuracy\n",
      "0.9992022524636321\n",
      "True positive rate, is fraud\n",
      "0.78125\n",
      "True positive rate, is not fraud\n",
      "0.9996121297602256\n"
     ]
    }
   ],
   "source": [
    "# SVMLIB format\n",
    "!rm -r libsvm/\n",
    "r = raw.rdd.map(lambda line:LabeledPoint(line[-1], Vectors.dense(line[3:35])))\n",
    "MLUtils.saveAsLibSVMFile(r, \"libsvm/\")\n",
    "libsvm = spark.read.format(\"libsvm\").load(\"libsvm/\")\n",
    "# libsvm.show(truncate = True)\n",
    "\n",
    "# Normalize\n",
    "scaler = StandardScaler(inputCol = \"features\", outputCol = \"norm_features\",\n",
    "                        withStd = True, withMean = True)\n",
    "scaler_model = scaler.fit(libsvm)\n",
    "libsvm = scaler_model.transform(libsvm)\n",
    "libsvm = libsvm.select(\"label\", \"norm_features\")\n",
    "libsvm = libsvm.withColumnRenamed(\"norm_features\", \"features\")\n",
    "# libsvm.show(truncate = False)\n",
    "\n",
    "# Classifier (MLP)\n",
    "data = libsvm\n",
    "# Train and test\n",
    "splits = data.randomSplit([0.7, 0.3], 1234)\n",
    "train = splits[0]\n",
    "test = splits[1]\n",
    "# Define network\n",
    "layers = [32, 23, 18, 2]\n",
    "trainer = MultilayerPerceptronClassifier(maxIter = 100, layers = layers, \n",
    "                                         blockSize = 128, seed = 1234)\n",
    "# Training.\n",
    "print(\"Training...\")\n",
    "model = trainer.fit(train)\n",
    "# Accuracy of test\n",
    "print(\"Testing...\")\n",
    "result = model.transform(test)\n",
    "predictionAndLabels = result.select(\"prediction\", \"label\")\n",
    "evaluator = MulticlassClassificationEvaluator(metricName = \"accuracy\")\n",
    "print(\"Test set accuracy = \" + str(evaluator.evaluate(predictionAndLabels)))\n",
    "\n",
    "# Metrics\n",
    "metrics = MulticlassMetrics(predictionAndLabels.rdd)\n",
    "\n",
    "print(\"Confusion matrix\")\n",
    "print(metrics.confusionMatrix().toArray())\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator()\n",
    "evaluator.setPredictionCol(\"prediction\")\n",
    "\n",
    "print(\"Accuracy\")\n",
    "print(evaluator.evaluate(predictionAndLabels, {evaluator.metricName: \"accuracy\"}))\n",
    "print(\"True positive rate, is fraud\")\n",
    "print(evaluator.evaluate(predictionAndLabels, {evaluator.metricName: \"truePositiveRateByLabel\",\n",
    "    evaluator.metricLabel: 1.0}))\n",
    "print(\"True positive rate, is not fraud\")\n",
    "print(evaluator.evaluate(predictionAndLabels, {evaluator.metricName: \"truePositiveRateByLabel\",\n",
    "    evaluator.metricLabel: 0.0}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## v. Dimensionality Reduction PCA (k = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Testing...\n",
      "Test set accuracy = 0.9991670577193805\n",
      "Confusion matrix\n",
      "[[8.5066e+04 1.4000e+01]\n",
      " [5.7000e+01 1.0300e+02]]\n",
      "Accuracy\n",
      "0.9991670577193805\n",
      "True positive rate, is fraud\n",
      "0.64375\n",
      "True positive rate, is not fraud\n",
      "0.9998354489891866\n"
     ]
    }
   ],
   "source": [
    "# SVMLIB format\n",
    "!rm -r libsvm/\n",
    "r = raw.rdd.map(lambda line:LabeledPoint(line[-1], Vectors.dense(line[3:35])))\n",
    "MLUtils.saveAsLibSVMFile(r, \"libsvm/\")\n",
    "libsvm = spark.read.format(\"libsvm\").load(\"libsvm/\")\n",
    "# libsvm.show(truncate = True)\n",
    "\n",
    "# PCA\n",
    "pca = PCA(k = 10, inputCol = \"features\", outputCol = \"pca_features\")\n",
    "model = pca.fit(libsvm)\n",
    "libsvm = model.transform(libsvm)\n",
    "libsvm = libsvm.select(\"label\", \"pca_features\")\n",
    "libsvm = libsvm.withColumnRenamed(\"pca_features\", \"features\")\n",
    "# libsvm.show(1, truncate = False)\n",
    "\n",
    "# Classifier (MLP)\n",
    "data = libsvm\n",
    "# Train and test\n",
    "splits = data.randomSplit([0.7, 0.3], 1234)\n",
    "train = splits[0]\n",
    "test = splits[1]\n",
    "# Define network\n",
    "layers = [10, 15, 12, 2]\n",
    "trainer = MultilayerPerceptronClassifier(maxIter = 100, layers = layers, \n",
    "                                         blockSize = 128, seed = 1234)\n",
    "# Training.\n",
    "print(\"Training...\")\n",
    "model = trainer.fit(train)\n",
    "# Accuracy of test\n",
    "print(\"Testing...\")\n",
    "result = model.transform(test)\n",
    "predictionAndLabels = result.select(\"prediction\", \"label\")\n",
    "evaluator = MulticlassClassificationEvaluator(metricName = \"accuracy\")\n",
    "print(\"Test set accuracy = \" + str(evaluator.evaluate(predictionAndLabels)))\n",
    "\n",
    "# Metrics\n",
    "metrics = MulticlassMetrics(predictionAndLabels.rdd)\n",
    "\n",
    "print(\"Confusion matrix\")\n",
    "print(metrics.confusionMatrix().toArray())\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator()\n",
    "evaluator.setPredictionCol(\"prediction\")\n",
    "\n",
    "print(\"Accuracy\")\n",
    "print(evaluator.evaluate(predictionAndLabels, {evaluator.metricName: \"accuracy\"}))\n",
    "print(\"True positive rate, is fraud\")\n",
    "print(evaluator.evaluate(predictionAndLabels, {evaluator.metricName: \"truePositiveRateByLabel\",\n",
    "    evaluator.metricLabel: 1.0}))\n",
    "print(\"True positive rate, is not fraud\")\n",
    "print(evaluator.evaluate(predictionAndLabels, {evaluator.metricName: \"truePositiveRateByLabel\",\n",
    "    evaluator.metricLabel: 0.0}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## v. 33 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Testing...\n",
      "Test set accuracy = 0.999296129887498\n",
      "Confusion matrix\n",
      "[[8.5076e+04 2.5000e+01]\n",
      " [3.5000e+01 1.0700e+02]]\n",
      "Accuracy\n",
      "0.999296129887498\n",
      "True positive rate, is fraud\n",
      "0.7535211267605634\n",
      "True positive rate, is not fraud\n",
      "0.9997062314191373\n"
     ]
    }
   ],
   "source": [
    "# SVMLIB format\n",
    "!rm -r libsvm/\n",
    "r = raw.rdd.map(lambda line:LabeledPoint(line[-1], Vectors.dense(line[2:35])))\n",
    "MLUtils.saveAsLibSVMFile(r, \"libsvm/\")\n",
    "libsvm = spark.read.format(\"libsvm\").load(\"libsvm/\")\n",
    "# libsvm.show(truncate = True)\n",
    "\n",
    "# Classifier (MLP)\n",
    "data = libsvm\n",
    "# Train and test splits.\n",
    "splits = data.randomSplit([0.7, 0.3], 1234)\n",
    "train = splits[0]\n",
    "test = splits[1]\n",
    "# Define network\n",
    "layers = [33, 23, 18, 2]\n",
    "trainer = MultilayerPerceptronClassifier(maxIter = 100, layers = layers, \n",
    "                                         blockSize = 128, seed = 1234)\n",
    "# Training.\n",
    "print(\"Training...\")\n",
    "model = trainer.fit(train)\n",
    "# Accuracy of test.\n",
    "print(\"Testing...\")\n",
    "result = model.transform(test)\n",
    "predictionAndLabels = result.select(\"prediction\", \"label\")\n",
    "evaluator = MulticlassClassificationEvaluator(metricName = \"accuracy\")\n",
    "print(\"Test set accuracy = \" + str(evaluator.evaluate(predictionAndLabels)))\n",
    "\n",
    "# Metrics \n",
    "metrics = MulticlassMetrics(predictionAndLabels.rdd)\n",
    "\n",
    "print(\"Confusion matrix\")\n",
    "print(metrics.confusionMatrix().toArray())\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator()\n",
    "evaluator.setPredictionCol(\"prediction\")\n",
    "\n",
    "print(\"Accuracy\")\n",
    "print(evaluator.evaluate(predictionAndLabels, {evaluator.metricName: \"accuracy\"}))\n",
    "print(\"True positive rate, is fraud\")\n",
    "print(evaluator.evaluate(predictionAndLabels, {evaluator.metricName: \"truePositiveRateByLabel\",\n",
    "    evaluator.metricLabel: 1.0}))\n",
    "print(\"True positive rate, is not fraud\")\n",
    "print(evaluator.evaluate(predictionAndLabels, {evaluator.metricName: \"truePositiveRateByLabel\",\n",
    "    evaluator.metricLabel: 0.0}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
